function [y1] = neural_net(x1)
%NEURAL_NET neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 28-Nov-2015 03:25:50.
% 
% [y1] = neural_net(x1) takes these arguments:
%   x = 12xQ matrix, input #1
% and returns:
%   y = 2xQ matrix, output #1
% where Q is the number of samples.

%#ok<*RPMT0>

  % ===== NEURAL NETWORK CONSTANTS =====
  
  % Input 1
  x1_step1_xoffset = [-2.08797774911884;-36.5834763642177;2.48177150762812;-50.9750011175914;0.581755371905877;-49.7803995362286;5.08560201355282;-43.7774864345304;-14.0132047233171;-40.8614565160913;-7.13823133927105;-30.1779828230228];
  x1_step1_gain = [0.0890442425419522;0.0835934202150888;0.0658572860394974;0.0579059147971087;0.0401640704238561;0.0372661057630946;0.0423322732978614;0.0413378524545075;0.0369325947152938;0.0404099446174239;0.0431968736026172;0.0455867601264552];
  x1_step1_ymin = -1;
  
  % Layer 1
  b1 = [1.6814320331812027;-1.429420627381129;1.2165203911163582;0.53931301267188159;-0.5622902200287756;1.3188587557757709;-0.787578115730725;-0.81586767239183533;-1.1842319170141935;1.6756294134117664];
  IW1_1 = [-0.12222627256992707 0.07590441729718872 -0.3471881490336024 0.42998376559935719 -0.83916740864730188 0.47765085042639233 0.43681296922126323 0.56106109603805443 -0.096811301766963884 -0.93173789995215195 0.58806559386398793 -0.18358953664487729;0.32814206073669999 -0.53101854429666928 0.89208320108170536 -0.52276824044374048 0.21824333155354073 0.36664415340613477 0.47194360743372665 0.076346063361354244 -0.28271856687447933 0.053691833151223917 0.78047826939824927 -0.18346092106805306;-0.71482822769565857 -0.65773995162746501 -0.36779275594090588 0.14672826112336704 -0.28649124206357701 0.055574274034656611 1.1520001528989683 0.92896730654300042 -0.3976999354664062 -0.89545555905682472 -0.34808262958116981 -0.43643687799466652;-0.44284901331983212 0.68549728065616955 -0.14802517470708368 -0.49093482288091445 0.81582650180837601 -0.44495740874310674 0.060310962166265539 -0.87764494472261856 -0.29397760325546796 0.5068327918043638 0.89019372575925437 -0.18340527417891103;-1.2711961050057188 -0.9789319723900739 -1.587367124230793 -1.4863989509657767 -0.52291211433703988 0.20836964285222415 0.49933606373081402 0.17669787159343497 -0.033958955210231317 1.2211550068540364 0.33150016195795096 0.54475634727667555;2.4932109306273214 -0.41040300132738372 3.0815429481812822 1.0767480398479949 1.9981466548811257 -1.3912550161553965 0.58258755877474266 -1.5048353675950832 1.7877218199733127 -1.6187794436183618 -0.71607168973025226 -0.96162049701475805;-1.5068985346369532 0.32311006392254871 -1.4285488679921394 -0.83058929698697259 -0.97013495338482547 1.0803072993837093 -0.095811385597926194 0.29453327318738964 -0.14605399776261552 0.80122585346080522 -0.021217327253220567 1.0114907735396705;-0.64115289543813947 0.83155681785284341 -0.44089535473151531 0.32367786037345259 0.39913571197371717 -0.15227344599300124 -1.05928642124268 0.46698381642217396 -0.048475551248573272 1.2132351318688823 0.53376070470787063 -0.10099723442312943;-0.72807338177987513 -0.40788848723607746 0.051562965574579817 0.099260971374586338 0.57322882268935771 -0.49748994412923914 0.49002070802826803 0.68889700497210471 0.073583680215055139 0.50671310908223643 -0.93620122659856653 0.35884965208543473;0.38892317246433117 0.86732105608634213 -0.79319066005313532 0.59651257281357806 -0.43022774671210767 -0.43987510681626429 0.56767213026018215 -0.3206901170855061 -0.30540661303924543 -0.20475821253610937 -0.20317038463865286 0.028637296274758473];
  
  % Layer 2
  b2 = [-0.011268338794568364;0.45135429023836765];
  LW2_1 = [0.54068568143743923 0.016019536403896389 -0.2616360734583858 -1.1685493338296142 1.9962443301617507 -4.8106656961254091 2.0576985876127543 0.23090785658959501 -0.043931827890877941 0.25784845370536319;0.86531983586557437 0.57952340045927209 1.6422498444371936 -0.1013820297036048 -2.1231998943546935 4.2033291439602687 -1.8573479201694643 -1.5575483960786467 -0.68173287562246121 -0.073290200815442949];
  
  % Output 1
  y1_step1_ymin = -1;
  y1_step1_gain = [2;2];
  y1_step1_xoffset = [0;0];
  
  % ===== SIMULATION ========
  
  % Dimensions
  Q = size(x1,2); % samples
  
  % Input 1
  xp1 = mapminmax_apply(x1,x1_step1_gain,x1_step1_xoffset,x1_step1_ymin);
  
  % Layer 1
  a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*xp1);
  
  % Layer 2
  a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
  
  % Output 1
  y1 = mapminmax_reverse(a2,y1_step1_gain,y1_step1_xoffset,y1_step1_ymin);
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings_gain,settings_xoffset,settings_ymin)
  y = bsxfun(@minus,x,settings_xoffset);
  y = bsxfun(@times,y,settings_gain);
  y = bsxfun(@plus,y,settings_ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n)
  nmax = max(n,[],1);
  n = bsxfun(@minus,n,nmax);
  numer = exp(n);
  denom = sum(numer,1); 
  denom(denom == 0) = 1;
  a = bsxfun(@rdivide,numer,denom);
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n)
  a = 2 ./ (1 + exp(-2*n)) - 1;
end

% Map Minimum and Maximum Output Reverse-Processing Function
function x = mapminmax_reverse(y,settings_gain,settings_xoffset,settings_ymin)
  x = bsxfun(@minus,y,settings_ymin);
  x = bsxfun(@rdivide,x,settings_gain);
  x = bsxfun(@plus,x,settings_xoffset);
end
